{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edb1120f-a0c8-445d-90ae-ccc2eb4d6586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from ast import literal_eval\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ea6ba18-22ca-404f-8acb-4eba265a0908",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"../dataset\"\n",
    "DATASET_NAME = \"medium_articles.csv\"\n",
    "DATASET_PATH = Path(DATASET_DIR) / DATASET_NAME\n",
    "\n",
    "assert Path(DATASET_PATH).exists(), \"Dataset not found.\"\n",
    "\n",
    "df = pd.read_csv(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a94d9174-a137-43a3-9913-c622fe887924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>authors</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mental Note Vol. 24</td>\n",
       "      <td>Photo by Josh Riemer on Unsplash\\n\\nMerry Chri...</td>\n",
       "      <td>https://medium.com/invisible-illness/mental-no...</td>\n",
       "      <td>['Ryan Fan']</td>\n",
       "      <td>2020-12-26 03:38:10.479000+00:00</td>\n",
       "      <td>['Mental Health', 'Health', 'Psychology', 'Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your Brain On Coronavirus</td>\n",
       "      <td>Your Brain On Coronavirus\\n\\nA guide to the cu...</td>\n",
       "      <td>https://medium.com/age-of-awareness/how-the-pa...</td>\n",
       "      <td>['Simon Spichak']</td>\n",
       "      <td>2020-09-23 22:10:17.126000+00:00</td>\n",
       "      <td>['Mental Health', 'Coronavirus', 'Science', 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mind Your Nose</td>\n",
       "      <td>Mind Your Nose\\n\\nHow smell training can chang...</td>\n",
       "      <td>https://medium.com/neodotlife/mind-your-nose-f...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-10-10 20:17:37.132000+00:00</td>\n",
       "      <td>['Biotechnology', 'Neuroscience', 'Brain', 'We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The 4 Purposes of Dreams</td>\n",
       "      <td>Passionate about the synergy between science a...</td>\n",
       "      <td>https://medium.com/science-for-real/the-4-purp...</td>\n",
       "      <td>['Eshan Samaranayake']</td>\n",
       "      <td>2020-12-21 16:05:19.524000+00:00</td>\n",
       "      <td>['Health', 'Neuroscience', 'Mental Health', 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Surviving a Rod Through the Head</td>\n",
       "      <td>You’ve heard of him, haven’t you? Phineas Gage...</td>\n",
       "      <td>https://medium.com/live-your-life-on-purpose/s...</td>\n",
       "      <td>['Rishav Sinha']</td>\n",
       "      <td>2020-02-26 00:01:01.576000+00:00</td>\n",
       "      <td>['Brain', 'Health', 'Development', 'Psychology...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title  \\\n",
       "0               Mental Note Vol. 24   \n",
       "1         Your Brain On Coronavirus   \n",
       "2                    Mind Your Nose   \n",
       "3          The 4 Purposes of Dreams   \n",
       "4  Surviving a Rod Through the Head   \n",
       "\n",
       "                                                text  \\\n",
       "0  Photo by Josh Riemer on Unsplash\\n\\nMerry Chri...   \n",
       "1  Your Brain On Coronavirus\\n\\nA guide to the cu...   \n",
       "2  Mind Your Nose\\n\\nHow smell training can chang...   \n",
       "3  Passionate about the synergy between science a...   \n",
       "4  You’ve heard of him, haven’t you? Phineas Gage...   \n",
       "\n",
       "                                                 url                 authors  \\\n",
       "0  https://medium.com/invisible-illness/mental-no...            ['Ryan Fan']   \n",
       "1  https://medium.com/age-of-awareness/how-the-pa...       ['Simon Spichak']   \n",
       "2  https://medium.com/neodotlife/mind-your-nose-f...                      []   \n",
       "3  https://medium.com/science-for-real/the-4-purp...  ['Eshan Samaranayake']   \n",
       "4  https://medium.com/live-your-life-on-purpose/s...        ['Rishav Sinha']   \n",
       "\n",
       "                          timestamp  \\\n",
       "0  2020-12-26 03:38:10.479000+00:00   \n",
       "1  2020-09-23 22:10:17.126000+00:00   \n",
       "2  2020-10-10 20:17:37.132000+00:00   \n",
       "3  2020-12-21 16:05:19.524000+00:00   \n",
       "4  2020-02-26 00:01:01.576000+00:00   \n",
       "\n",
       "                                                tags  \n",
       "0  ['Mental Health', 'Health', 'Psychology', 'Sci...  \n",
       "1  ['Mental Health', 'Coronavirus', 'Science', 'P...  \n",
       "2  ['Biotechnology', 'Neuroscience', 'Brain', 'We...  \n",
       "3  ['Health', 'Neuroscience', 'Mental Health', 'P...  \n",
       "4  ['Brain', 'Health', 'Development', 'Psychology...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f9ade0-8f1a-48ca-9eb9-14cb4a30c487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title        192363\n",
       "text         192368\n",
       "url          192368\n",
       "authors      192368\n",
       "timestamp    192366\n",
       "tags         192368\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0f6982c-21df-4749-a7f2-f9e93e23597c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'text', 'url', 'authors', 'timestamp', 'tags'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7758063-dd96-475f-975c-fc27fe0e400b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 192368/192368 [00:02<00:00, 83174.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [Mental Health, Health, Psychology, Science, N...\n",
       "1    [Mental Health, Coronavirus, Science, Psycholo...\n",
       "2    [Biotechnology, Neuroscience, Brain, Wellness,...\n",
       "3    [Health, Neuroscience, Mental Health, Psycholo...\n",
       "4    [Brain, Health, Development, Psychology, Science]\n",
       "Name: tags, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df = df.tags.progress_apply(literal_eval)\n",
    "tags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb84f595-92db-490e-a623-ec20d17ff4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 192368/192368 [00:00<00:00, 985983.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78638"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = set()\n",
    "\n",
    "tags_df.progress_apply(\n",
    "    lambda x: labels.update(x)\n",
    ")\n",
    "\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "337619d3-ad73-4fb9-bef2-be47d0e2b3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_vals = list(filter(bool, labels))\n",
    "label_df = pd.DataFrame(\n",
    "    {\n",
    "        \"index\": range(1, len(label_vals) + 1),\n",
    "        \"label\": label_vals\n",
    "    },\n",
    ")\n",
    "label_df = label_df[~label_df[\"label\"].str.lower().duplicated()]\n",
    "label_df = pd.DataFrame(\n",
    "    {\n",
    "        \"index\": range(1, label_df[\"label\"].count() + 1),\n",
    "        \"label\": label_df[\"label\"].tolist()\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce405fbb-3b35-4665-9ddb-324ad6fa717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dataset_path = Path(DATASET_DIR) / \"labels.parquet\"\n",
    "label_df.to_parquet(label_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c23013ad-06dc-43d9-8dce-8caad6733e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Apache Httpd\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = pd.read_parquet(label_dataset_path)\n",
    "label_df[label_df[\"index\"] == 1].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb49d23d-7aaf-4098-82b5-437ee589a4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c034f0ff-4dfd-49ad-b47a-12f58b61f047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Eytech',\n",
       " 'Used Cars For Sale',\n",
       " 'Connector User',\n",
       " 'Deep Dives',\n",
       " 'Uncomfortable Joy',\n",
       " '100dayproject',\n",
       " 'Impotence',\n",
       " 'Pearson',\n",
       " 'Discount Vouchers',\n",
       " 'Facebook Notes',\n",
       " 'Fluttering Up',\n",
       " 'Management Tips',\n",
       " 'Unhcr',\n",
       " 'Discipleship',\n",
       " 'Cancer Survivor',\n",
       " 'Apprenticeship',\n",
       " 'Voices',\n",
       " 'Eventfiringwebdriver',\n",
       " 'Value Time Matrix',\n",
       " 'Wound Care Biologics',\n",
       " 'Grades',\n",
       " 'MVP',\n",
       " 'Things I Wish I Knew',\n",
       " 'Watertech',\n",
       " 'Preterm Birth',\n",
       " 'Timothy Patrick Lloyd',\n",
       " '盆栽',\n",
       " 'New Hampshire',\n",
       " 'Lazy',\n",
       " 'Perceptron Algorithm',\n",
       " 'License Compliance',\n",
       " 'Screen Recording',\n",
       " 'Onlineshoppinginpakistan',\n",
       " 'Creative Economy',\n",
       " 'B2b Lead Generation Usa',\n",
       " 'Murder For Hire',\n",
       " 'Ugly Christmas',\n",
       " 'Ideasworthsharing',\n",
       " 'Accordions',\n",
       " 'Markets In Action',\n",
       " 'True Wealth',\n",
       " 'Angular Ui Design',\n",
       " 'Crypto Wallet',\n",
       " 'New Tech Startup',\n",
       " 'Underserved Communities',\n",
       " 'Oversensitivity',\n",
       " 'Mandy Patinkin',\n",
       " 'Best Security System',\n",
       " 'Vacations',\n",
       " 'Pwa',\n",
       " 'Tech Awards',\n",
       " 'Package Manager',\n",
       " 'Third Way',\n",
       " 'Borderline Personality',\n",
       " 'Sony Vaio',\n",
       " 'Onlinedating',\n",
       " 'Propose Day',\n",
       " 'Email Marketing Tools',\n",
       " 'Editors Pick',\n",
       " 'Trusted',\n",
       " 'Wellness Programs',\n",
       " 'Lemon Influencer',\n",
       " 'Snl Performer',\n",
       " 'Forex Trading For Newbies',\n",
       " 'The Cw',\n",
       " 'Historias',\n",
       " 'Social Technology',\n",
       " 'Kris',\n",
       " 'Dalagang Pilipina',\n",
       " 'Reward',\n",
       " 'Organizational Health',\n",
       " 'Fellowship Writers',\n",
       " 'Airight',\n",
       " 'Perfect',\n",
       " 'Computer Memories',\n",
       " 'Shortcuts',\n",
       " 'Adhd Help',\n",
       " 'Pansexual',\n",
       " 'Clean Vs Explicit',\n",
       " 'Teacher Voice',\n",
       " 'Django Logging Queries',\n",
       " 'Pipe Manufacturer',\n",
       " 'Airdorp',\n",
       " 'Vaginal Rejuvenation',\n",
       " 'Rebel Wisdom',\n",
       " 'Codingurukul',\n",
       " 'Season 5 Episode 6',\n",
       " 'Cat Adoption',\n",
       " 'Rape Myths',\n",
       " 'Bytecode',\n",
       " 'Instagram Coach',\n",
       " 'Filthy Lucre',\n",
       " 'Image Super Resolution',\n",
       " 'React Performance',\n",
       " 'Sailing Ship',\n",
       " 'Coffee Freshness',\n",
       " 'Conscious Consumption',\n",
       " 'Enterprise Erp',\n",
       " 'Wearables',\n",
       " 'Veriokuryazarlığı']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_vals[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ada0e8e-3929-4dda-8d97-7d9d180dbfb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"papluca/xlm-roberta-base-language-detection\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"papluca/xlm-roberta-base-language-detection\")\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ed546b9-9463-49c8-8d58-5e538ea60586",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Trade S\", return_tensors=\"pt\")\n",
    "for k, v in inputs.items():\n",
    "    inputs[k] = v.to(device)\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce97a15f-ea9c-4679-97fd-e5c2499ee131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-1.0156,  0.6120, -1.2223, -0.5868, -0.3044,  0.3479,  1.4802,  0.4988,\n",
       "         -1.1956,  0.7597, -0.3993,  2.8324, -0.3252,  1.8733, -1.2812, -1.2442,\n",
       "         -0.1646, -0.3289,  0.6719, -0.9912]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "230d7440-57a7-41c8-a36b-f48a0bfde851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "# mps_available = hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available()\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59b7d4d0-a759-4a1b-87c5-b14f5c86add5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'en', 'score': 0.8340853452682495}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Mental Health\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acd8e359-2160-4133-9681-853fc0f35204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_list = list(map(lambda s: s[:514], df[\"text\"].iloc[-100:].tolist()))\n",
    "# pipe(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33dc8370-2d60-4b57-9443-5734ce40a233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c72d7fe440941789aaf993732450501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import List\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "en_labels = []\n",
    "\n",
    "class EnLabelDataset(Dataset):\n",
    "    def __init__(self, data: List[str]) -> None:\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> str:\n",
    "        return self.data[idx]\n",
    "\n",
    "dataset = EnLabelDataset(label_vals)\n",
    "\n",
    "for out in tqdm(pipe(dataset, batch_size=1000), total=len(dataset)):\n",
    "    en_labels.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7cc89dc-ac62-4729-84a1-b502c5875a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.DataFrame(en_labels).rename(\n",
    "    columns={\"label\": \"lang_label\", \"score\": \"lang_score\"},\n",
    ").assign(\n",
    "    label=label_vals,\n",
    "    index=range(1, len(label_vals) + 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbe12d51-135a-42d6-a448-de2817a00662",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dataset_path = Path(DATASET_DIR) / \"en_labels.parquet\"\n",
    "label_df.to_parquet(label_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9eeefdc8-f570-45f6-938b-382fdafc9ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_label</th>\n",
       "      <th>lang_score</th>\n",
       "      <th>label</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi</td>\n",
       "      <td>0.718276</td>\n",
       "      <td>Apache Httpd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>0.929937</td>\n",
       "      <td>Over 50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>0.925368</td>\n",
       "      <td>Air Fryer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pt</td>\n",
       "      <td>0.526477</td>\n",
       "      <td>Adar Poonawalla</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>0.621760</td>\n",
       "      <td>Macabre</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78632</th>\n",
       "      <td>en</td>\n",
       "      <td>0.964156</td>\n",
       "      <td>Coffee Freshness</td>\n",
       "      <td>78633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78633</th>\n",
       "      <td>en</td>\n",
       "      <td>0.992965</td>\n",
       "      <td>Conscious Consumption</td>\n",
       "      <td>78634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78634</th>\n",
       "      <td>tr</td>\n",
       "      <td>0.372506</td>\n",
       "      <td>Enterprise Erp</td>\n",
       "      <td>78635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78635</th>\n",
       "      <td>en</td>\n",
       "      <td>0.990927</td>\n",
       "      <td>Wearables</td>\n",
       "      <td>78636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78636</th>\n",
       "      <td>tr</td>\n",
       "      <td>0.994708</td>\n",
       "      <td>Veriokuryazarlığı</td>\n",
       "      <td>78637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78637 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lang_label  lang_score                  label  index\n",
       "0             hi    0.718276           Apache Httpd      1\n",
       "1             en    0.929937                Over 50      2\n",
       "2             en    0.925368              Air Fryer      3\n",
       "3             pt    0.526477        Adar Poonawalla      4\n",
       "4             en    0.621760                Macabre      5\n",
       "...          ...         ...                    ...    ...\n",
       "78632         en    0.964156       Coffee Freshness  78633\n",
       "78633         en    0.992965  Conscious Consumption  78634\n",
       "78634         tr    0.372506         Enterprise Erp  78635\n",
       "78635         en    0.990927              Wearables  78636\n",
       "78636         tr    0.994708      Veriokuryazarlığı  78637\n",
       "\n",
       "[78637 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ef0b764-7722-4f3c-888d-0f960fb26020",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65c39c03-32b5-470f-b1eb-676c1b537835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                   | 996/192368 [00:00<00:19, 9955.24it/s]/home/ntub/Documents/190k-medium-articles/.venv/lib/python3.9/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "  2%|▋                                  | 3913/192368 [00:00<00:19, 9585.63it/s]/home/ntub/Documents/190k-medium-articles/.venv/lib/python3.9/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      "/home/ntub/Documents/190k-medium-articles/.venv/lib/python3.9/site-packages/bs4/builder/_htmlparser.py:105: UserWarning: unknown status keyword 'A-Z' in marked section\n",
      "  warnings.warn(msg)\n",
      "100%|████████████████████████████████| 192368/192368 [00:18<00:00, 10405.53it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_text(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    text = re.sub(r'https?://\\S+', ' ', text) # 去除網址\n",
    "    text = re.sub(r'[^a-zA-Z0-9 .,:;\\'\\\"\\(\\)\\[\\]\\{\\}]', ' ', text) # 去除非字母、非數字和非空白字符\n",
    "    return text\n",
    "\n",
    "df[\"text\"] = df[\"text\"].progress_apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "948c5aa9-7f4a-4c82-a01f-38f63c4213f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>authors</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mental Note Vol. 24</td>\n",
       "      <td>Photo by Josh Riemer on Unsplash  Merry Christ...</td>\n",
       "      <td>https://medium.com/invisible-illness/mental-no...</td>\n",
       "      <td>['Ryan Fan']</td>\n",
       "      <td>2020-12-26 03:38:10.479000+00:00</td>\n",
       "      <td>['Mental Health', 'Health', 'Psychology', 'Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your Brain On Coronavirus</td>\n",
       "      <td>Your Brain On Coronavirus  A guide to the curi...</td>\n",
       "      <td>https://medium.com/age-of-awareness/how-the-pa...</td>\n",
       "      <td>['Simon Spichak']</td>\n",
       "      <td>2020-09-23 22:10:17.126000+00:00</td>\n",
       "      <td>['Mental Health', 'Coronavirus', 'Science', 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mind Your Nose</td>\n",
       "      <td>Mind Your Nose  How smell training can change ...</td>\n",
       "      <td>https://medium.com/neodotlife/mind-your-nose-f...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-10-10 20:17:37.132000+00:00</td>\n",
       "      <td>['Biotechnology', 'Neuroscience', 'Brain', 'We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The 4 Purposes of Dreams</td>\n",
       "      <td>Passionate about the synergy between science a...</td>\n",
       "      <td>https://medium.com/science-for-real/the-4-purp...</td>\n",
       "      <td>['Eshan Samaranayake']</td>\n",
       "      <td>2020-12-21 16:05:19.524000+00:00</td>\n",
       "      <td>['Health', 'Neuroscience', 'Mental Health', 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Surviving a Rod Through the Head</td>\n",
       "      <td>You ve heard of him, haven t you  Phineas Gage...</td>\n",
       "      <td>https://medium.com/live-your-life-on-purpose/s...</td>\n",
       "      <td>['Rishav Sinha']</td>\n",
       "      <td>2020-02-26 00:01:01.576000+00:00</td>\n",
       "      <td>['Brain', 'Health', 'Development', 'Psychology...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title  \\\n",
       "0               Mental Note Vol. 24   \n",
       "1         Your Brain On Coronavirus   \n",
       "2                    Mind Your Nose   \n",
       "3          The 4 Purposes of Dreams   \n",
       "4  Surviving a Rod Through the Head   \n",
       "\n",
       "                                                text  \\\n",
       "0  Photo by Josh Riemer on Unsplash  Merry Christ...   \n",
       "1  Your Brain On Coronavirus  A guide to the curi...   \n",
       "2  Mind Your Nose  How smell training can change ...   \n",
       "3  Passionate about the synergy between science a...   \n",
       "4  You ve heard of him, haven t you  Phineas Gage...   \n",
       "\n",
       "                                                 url                 authors  \\\n",
       "0  https://medium.com/invisible-illness/mental-no...            ['Ryan Fan']   \n",
       "1  https://medium.com/age-of-awareness/how-the-pa...       ['Simon Spichak']   \n",
       "2  https://medium.com/neodotlife/mind-your-nose-f...                      []   \n",
       "3  https://medium.com/science-for-real/the-4-purp...  ['Eshan Samaranayake']   \n",
       "4  https://medium.com/live-your-life-on-purpose/s...        ['Rishav Sinha']   \n",
       "\n",
       "                          timestamp  \\\n",
       "0  2020-12-26 03:38:10.479000+00:00   \n",
       "1  2020-09-23 22:10:17.126000+00:00   \n",
       "2  2020-10-10 20:17:37.132000+00:00   \n",
       "3  2020-12-21 16:05:19.524000+00:00   \n",
       "4  2020-02-26 00:01:01.576000+00:00   \n",
       "\n",
       "                                                tags  \n",
       "0  ['Mental Health', 'Health', 'Psychology', 'Sci...  \n",
       "1  ['Mental Health', 'Coronavirus', 'Science', 'P...  \n",
       "2  ['Biotechnology', 'Neuroscience', 'Brain', 'We...  \n",
       "3  ['Health', 'Neuroscience', 'Mental Health', 'P...  \n",
       "4  ['Brain', 'Health', 'Development', 'Psychology...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60c8f6dc-449b-472f-a23c-364010624c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2328c4c73b9e497995286012acf58ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192368 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import List\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame) -> None:\n",
    "        self.data = dataframe[\"text\"]\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return self.data.count()\n",
    "\n",
    "    def __getitem__(self, idx: int) -> str:\n",
    "        return self.data.iloc[idx][:514]\n",
    "\n",
    "dataset = SentenceDataset(df)\n",
    "\n",
    "for out in tqdm(pipe(dataset, batch_size=100), total=len(dataset)):\n",
    "    result.append(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fc78b15-b332-4749-826e-927ff5587d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1bedc78-0372-4862-b497-c0922ac933d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>0.964118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>0.962439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>0.957879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>0.915634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>0.914334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192363</th>\n",
       "      <td>en</td>\n",
       "      <td>0.955198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192364</th>\n",
       "      <td>en</td>\n",
       "      <td>0.993724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192365</th>\n",
       "      <td>en</td>\n",
       "      <td>0.984959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192366</th>\n",
       "      <td>en</td>\n",
       "      <td>0.978811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192367</th>\n",
       "      <td>en</td>\n",
       "      <td>0.992958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192368 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label     score\n",
       "0         en  0.964118\n",
       "1         en  0.962439\n",
       "2         en  0.957879\n",
       "3         en  0.915634\n",
       "4         en  0.914334\n",
       "...      ...       ...\n",
       "192363    en  0.955198\n",
       "192364    en  0.993724\n",
       "192365    en  0.984959\n",
       "192366    en  0.978811\n",
       "192367    en  0.992958\n",
       "\n",
       "[192368 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24a8a34e-3c98-4d46-ad59-ef95936bd844",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.concat([df, result_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac8d632a-be5a-4fed-858f-37d8527b52c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset_path = Path(DATASET_DIR) / \"medium_articles.parquet\"\n",
    "concat_df.to_parquet(new_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d52a32f7-5cf9-4b1b-bdd5-d025e93537bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Every teacher and professor had their share of strain brought by the ongoing COVID 19 pandemic.  Through listening, adaptation, and planning, we made it to the finish line with quite a bit of energy with my students this semester.  There was one key decision that helped me have a very smooth remote teaching experience: preparing a front loaded syllabus.  I made that choice consciously, but of course without a prediction about the implications of the then developing pandemic. I aimed to empower students with a broad spectrum of tools early in the semester and use the rest of the time for individual project development.  This strategy ended up working well for remote teaching.  Shaping a classroom through Agency, Adaptation, and Tooling  Over the years, I observed that front loaded classes and workshops fared much better in many terms. Combined with a longer exploration process, in the end, they turned into a teaching formula for achieving high yield, high quality results.  I prepared the syllabus for the 2020 spring semester for the class I taught at MIT s School of Architecture and Planning with three things in mind:  1  Agency  When you prepare a front loaded class or a workshop, you shock the students at their freshest state. This enables them to see a lot of material in a short period, but more importantly to pick and chose whatever makes more sense to them.  Yes, no student learns everything we try to teach and it is better if we empower them with the material they are interested in. This kind of agency helps students to become a more integral part of the teaching process.  If the teaching material is comprehensive and the teaching style is generous enough, students can and will have a say in what they learn. If the material is not malleable, they will either have a hard time adapting, or won t align with the classroom dynamics at all.  2  Adaptation  Teaching is about bi directional adaptation.  As the students adapt to the class and teaching material, the instructor needs to adapt to the overall drive of the class. Instructors are inclined to expect the students to adapt. But not all of them think about the fact that for a symbiosis to happen, both parties would need to act.  A front loaded class helps both parties to adjust and make choices early in the semester.  I revealed the goals and mechanics of the subject in the very first class and dived right into the material. With a fast follow up in the second week, I developed a quick sensation about the choices I made for the amount and delivery of the teaching material. In the meantime, the students came with questions to figure out if the class was the right one for them.  One other benefit of a fast paced start was to determine the no adaptation types move out quickly. At MIT the students  shop  for the classes the first week or two. If you show the intensity of the class early in the semester that helps refine the crowd.  In short, if you are open to change things on the course   which in my mind is a must   a front loaded class helps you plan earlier in the semester.  3  Fluency  If you are teaching a class that includes skill building components, there are fundamentally two tracks you can follow.  1   You can plan to move incrementally and distribute skill building sessions throughout the semester. This would help students to learn and digest skills over longer periods. A slower pace can also help them add skills more easily. This is a low stress and low risk choice, but it takes from the time that could be invested in the employment and refinement of skills.  2   Alternatively, you can front load the syllabus with skill building sessions and then observe the tendencies of students in picking things up. This is a riskier move as not all the students would be able to follow the pace of the class. Students may need more support when you want to add on top of something that you have already taught in class. This would put more work hours on the instructor.  Just looking at the overall picture, the first option appears to be more logical, as the safe bet. Yet the second option, although comes with some risks, increases the chances of break through achievements   if they are ever to happen in the class.  Moving within a fast paced setting, students hit a steeper learning curve, but at the same time become accustomed to the tools of the class earlier. This helps them become fluent in the tools they are using quicker.  Especially for an application and making oriented class, the second option works miraculously better.  How so   I learned how to teach over 15 years of piecemeal teaching  I have a quite mixed past in teaching and I have nowhere near the experience of a full time academician. Yet, jumping back and forth between academia and professional practice, or spending time in both simultaneously helped me translate the strategies of teaching across these two domains.  What did I do   I co taught design studios. I developed design, geometry, and scripting classes. I happened to initiate and lead an undergraduate design program, somehow early in my career.  Last but not the least, I conducted many workshops in different schools, cultures, and countries. Especially these workshops that ran anywhere from three hours to two weeks taught me a lot about developing syllabuses, even more so than semester long classes.  The diversity of student s backgrounds, ages, and interests taught me a lot as well. While in professional practice, I happened to teach people whose age was (more than) double of mine. Later, I found chances to teach fresh out of the high school kids.  Over and over again, I discovered front loaded scenarios fared better. Starting vertical (and going deep) and then going horizontal (and expanding).  I applied this strategy to my latest teaching adventure.  I asked the students to develop a  design  that had to be re thought, letting go of its preconceived  parts.  My motivation stemmed from my ever unfolding inquiry about part whole relationships that I explained in my latest story:  I deployed the teaching material through 4 tracks: Presence, Function, Quality, and The Whole.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df.iloc[1000][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edad5a27-3392-4af3-a7cb-b38fa3361c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
